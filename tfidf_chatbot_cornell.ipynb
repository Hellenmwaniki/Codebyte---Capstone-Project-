{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afdaabab",
   "metadata": {},
   "source": [
    "# TF-IDF + Cosine Similarity Chatbot (Cornell Movie Dialogs Corpus)\n",
    "A simple NLP chatbot using TF-IDF and cosine similarity for conversational response matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc65146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2cb024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Cornell Movie Dialogs Dataset\n",
    "conversations = pd.read_csv('original-data/movie_conversations.txt',sep=r'\\s*\\+\\+\\+\\$\\+\\+\\+\\s*',engine='python', names=[\"character1\", \"character2\", \"movieID\", \"utteranceIDs\"],encoding='iso-8859-1')\n",
    "lines = pd.read_csv('original-data/movie_lines.txt',sep=r'\\s*\\+\\+\\+\\$\\+\\+\\+\\s*',engine='python',names=[\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"],encoding='iso-8859-1')\n",
    "\n",
    "yt1= pd.read_csv('original-data/brian_youtube_data_comments.csv')\n",
    "yt2= pd.read_csv('original-data/pamela-youtube_comments.csv')\n",
    "\n",
    "# Convert utteranceIDs from string to list\n",
    "conversations['utteranceIDs'] = conversations['utteranceIDs'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4968bcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted 221282 conversation pairs.\n",
      "                                                    input  \\\n",
      "92511   Oh, okay, forgive me.  Your neighbors are here...   \n",
      "77948                                 So you're a lawyer.   \n",
      "18704                                             Oh, no.   \n",
      "7333    He suspects I know something. I think he was s...   \n",
      "128637  Don't recognize him. You were trapped by Morga...   \n",
      "\n",
      "                                                 response  \n",
      "92511              Exactly what I mean.  It's all ruined.  \n",
      "77948     That's right. What are you doing in Bodega Bay?  \n",
      "18704                      I knew you'd understand. Here.  \n",
      "7333                                                Why?!  \n",
      "128637  ...Gawain and Perceval, Bors and Bohort, Carad...  \n"
     ]
    }
   ],
   "source": [
    "#Extract Conversational Pairs (input-response)\n",
    "line_dict = dict(zip(lines['lineID'], lines['text']))\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for conv in conversations['utteranceIDs']:\n",
    "    for i in range(len(conv) - 1):\n",
    "        # Get both lines from the dictionary\n",
    "        in_line = line_dict.get(conv[i])\n",
    "        out_line = line_dict.get(conv[i+1])\n",
    "\n",
    "        # Ensure both exist and are strings\n",
    "        if isinstance(in_line, str) and isinstance(out_line, str):\n",
    "            in_line = in_line.strip()\n",
    "            out_line = out_line.strip()\n",
    "            if in_line and out_line:\n",
    "                pairs.append((in_line, out_line))\n",
    "\n",
    "# Create DataFrame\n",
    "chat_df = pd.DataFrame(pairs, columns=[\"input\", \"response\"])\n",
    "\n",
    "# Sanity check\n",
    "print(f\"✅ Extracted {len(chat_df)} conversation pairs.\")\n",
    "if not chat_df.empty:\n",
    "    print(chat_df.sample(5))\n",
    "else:\n",
    "    print(\"❌ No valid pairs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f329e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the Text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "chat_df['clean_input'] = chat_df['input'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c751f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF Matrix for User Inputs\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(chat_df['clean_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3821f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot Function Using Cosine Similarity\n",
    "def chatbot_response(user_input):\n",
    "    cleaned_input = clean_text(user_input)\n",
    "    user_vec = vectorizer.transform([cleaned_input])\n",
    "    similarities = cosine_similarity(user_vec, tfidf_matrix).flatten()\n",
    "    best_match_idx = similarities.argmax()\n",
    "    if similarities[best_match_idx] > 0:\n",
    "        return chat_df.iloc[best_match_idx]['response']\n",
    "    else:\n",
    "        return \"I'm not sure how to respond to that.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b8093eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Function that takes user input and returns chatbot response\n",
    "def chat_with_bot(user_input):\n",
    "    user_input_vector = vectorizer.transform([user_input])\n",
    "    similarity = cosine_similarity(user_input_vector, tfidf_matrix)\n",
    "    best_match_idx = similarity.argmax()\n",
    "    return chat_df.iloc[best_match_idx][\"response\"]\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(fn=chat_with_bot,\n",
    "                     inputs=gr.Textbox(lines=2, placeholder=\"Type a message...\"),\n",
    "                     outputs=\"text\",\n",
    "                     title=\"TF-IDF and cosine similarity baseline model\",\n",
    "                     description=\"Ask something and get a response based on similarity!\")\n",
    "\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4822daf2",
   "metadata": {},
   "source": [
    "## Why This Baseline Model Needs Further Advancement\n",
    "\n",
    "The current chatbot uses a TF-IDF (Term Frequency-Inverse Document Frequency) vectorizer combined with cosine similarity to find the most relevant response to a user's input. While this method is simple and effective as a baseline, it has several limitations that make it unsuitable for production-level conversational AI:\n",
    "\n",
    "### 1. **Lack of Context Awareness**\n",
    "The model treats each input-response pair as independent. It doesn't remember prior messages in the conversation, making it unable to maintain coherent multi-turn interactions.\n",
    "\n",
    "### 2. **No Semantic Understanding**\n",
    "TF-IDF relies purely on the frequency of words. It doesn’t understand the meaning behind words or recognize synonyms. For instance, \"How are you doing?\" and \"How's it going?\" might be treated as unrelated.\n",
    "\n",
    "### 3. **Rigid Matching**\n",
    "The model will fail to respond well to slightly rephrased, paraphrased, or typo-ridden inputs, since it depends on exact or partial word overlap.\n",
    "\n",
    "### 4. **Scalability Issues**\n",
    "As the dataset grows, cosine similarity computations become slower, especially with larger TF-IDF matrices. This limits performance in real-time applications.\n",
    "\n",
    "### 5. **No Personalization or Dynamic Learning**\n",
    "The model cannot adapt to different users, preferences, or conversation styles. It also doesn’t improve over time unless retrained.\n",
    "\n",
    "\n",
    "## Future Improvements\n",
    "\n",
    "To build a more intelligent and natural chatbot\n",
    "\n",
    "This baseline model is a great starting point for understanding chatbot mechanics, but it's only the first step toward building a truly intelligent conversational agent.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
