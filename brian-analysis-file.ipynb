{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d548cc",
   "metadata": {},
   "source": [
    "# Important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1354d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84afae7",
   "metadata": {},
   "source": [
    "# **Step 1: Load and Parse movie_lines.txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e4dc082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to map line IDs to text\n",
    "movie_lines_path = \"movie_lines.txt\"\n",
    "\n",
    "# A Dictionary to hold lineID -> text\n",
    "id2line = {}\n",
    "\n",
    "with open(movie_lines_path, encoding='utf-8', errors='ignore') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\" +++$+++ \")\n",
    "        if len(parts) == 5:\n",
    "            line_id, _, _, _, text = parts\n",
    "            id2line[line_id] = text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f540d0d5",
   "metadata": {},
   "source": [
    "# Step 2: Load and Parse movie_conversations.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e44ed6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract conversations (list of line IDs)\n",
    "movie_conversations_path = \"movie_conversations.txt\"\n",
    "\n",
    "conversations = []\n",
    "\n",
    "with open(movie_conversations_path, encoding='utf-8', errors='ignore') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\" +++$+++ \")\n",
    "        if len(parts) == 4:\n",
    "            line_ids_str = parts[3]\n",
    "            # Convert string to actual list of line IDs\n",
    "            line_ids = eval(line_ids_str)  # Safe here because the format is consistent\n",
    "            conversations.append(line_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6747dd86",
   "metadata": {},
   "source": [
    "# Step 3: Reconstruct Conversations from Line IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ad8ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a list of reconstructed conversations\n",
    "reconstructed_conversations = []\n",
    "\n",
    "for conv in conversations:\n",
    "    dialogue = []\n",
    "    for line_id in conv:\n",
    "        line_text = id2line.get(line_id, \"\")\n",
    "        dialogue.append(line_text)\n",
    "    reconstructed_conversations.append(dialogue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d560ba",
   "metadata": {},
   "source": [
    "# Step 4: View Sample Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40a8996d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation 1\n",
      "Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n",
      "Well, I thought we'd start with pronunciation, if that's okay with you.\n",
      "Not the hacking and gagging and spitting part.  Please.\n",
      "Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
      "\n",
      "Conversation 2\n",
      "You're asking me out.  That's so cute. What's your name again?\n",
      "Forget it.\n",
      "\n",
      "Conversation 3\n",
      "No, no, it's my fault -- we didn't have a proper introduction ---\n",
      "Cameron.\n",
      "The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\n",
      "Seems like she could get a date easy enough...\n"
     ]
    }
   ],
   "source": [
    "# Print the first 3 conversations\n",
    "for i, convo in enumerate(reconstructed_conversations[:3]):\n",
    "    print(f\"\\nConversation {i+1}\")\n",
    "    for turn in convo:\n",
    "        print(turn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432bbedc",
   "metadata": {},
   "source": [
    "# **Final: Saving to Text File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe2a4cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation 1\n",
      "Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n",
      "Well, I thought we'd start with pronunciation, if that's okay with you.\n",
      "Not the hacking and gagging and spitting part.  Please.\n",
      "Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
      "\n",
      "Conversation 2\n",
      "You're asking me out.  That's so cute. What's your name again?\n",
      "Forget it.\n",
      "\n",
      "Conversation 3\n",
      "No, no, it's my fault -- we didn't have a proper introduction ---\n",
      "Cameron.\n",
      "The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\n",
      "Seems like she could get a date easy enough...\n"
     ]
    }
   ],
   "source": [
    "# Print the first 3 conversations\n",
    "for i, convo in enumerate(reconstructed_conversations[:3]):\n",
    "    print(f\"\\nConversation {i+1}\")\n",
    "    for turn in convo:\n",
    "        print(turn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fbeb6c",
   "metadata": {},
   "source": [
    "## **Summary**\n",
    "\n",
    "- id2line maps line IDs to actual dialogue text.\n",
    "\n",
    "- conversations holds the sequences of line IDs per conversation.\n",
    "\n",
    "- reconstructed_conversations gives you the full text of the conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe16636e",
   "metadata": {},
   "source": [
    "# Setup: Parse & Reconstruct (from earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b0833a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse movie_lines.txt\n",
    "id2line = {}\n",
    "with open(\"movie_lines.txt\", encoding='utf-8', errors='ignore') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\" +++$+++ \")\n",
    "        if len(parts) == 5:\n",
    "            line_id, _, _, _, text = parts\n",
    "            id2line[line_id] = text\n",
    "\n",
    "# Parse movie_conversations.txt\n",
    "conversations = []\n",
    "with open(\"movie_conversations.txt\", encoding='utf-8', errors='ignore') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\" +++$+++ \")\n",
    "        if len(parts) == 4:\n",
    "            line_ids = eval(parts[3])\n",
    "            conversations.append(line_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151fe31f",
   "metadata": {},
   "source": [
    "# **Option A: One Row per Conversation (block of text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9c386",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Combine each conversation into one string\n",
    "conversation_texts = [\n",
    "    \"\\n\".join([id2line.get(line_id, \"\") for line_id in conv])\n",
    "    for conv in conversations\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_conversations = pd.DataFrame({\n",
    "    \"conversation_id\": list(range(len(conversation_texts))),\n",
    "    \"conversation_text\": conversation_texts\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df_conversations.to_csv(\"conversations_block.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83abb46",
   "metadata": {},
   "source": [
    "# **Option B: One Row per Line (dialogue turn)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25856486",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for conv_id, conv in enumerate(conversations):\n",
    "    for order, line_id in enumerate(conv):\n",
    "        line_text = id2line.get(line_id, \"\")\n",
    "        rows.append({\n",
    "            \"conversation_id\": conv_id,\n",
    "            \"line_order\": order,\n",
    "            \"line_text\": line_text\n",
    "        })\n",
    "\n",
    "df_lines = pd.DataFrame(rows)\n",
    "df_lines.to_csv(\"conversations_lines.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369f8c5d",
   "metadata": {},
   "source": [
    "**Done!**\n",
    "\n",
    "We now have:\n",
    "\n",
    "- conversations_block.csv: full conversations as text blocks.\n",
    "\n",
    "- conversations_lines.csv: every line of dialogue in its own row."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
