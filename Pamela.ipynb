{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f07984e",
   "metadata": {},
   "source": [
    "## Team Members \n",
    "\n",
    "1. Jessica Mutiso\n",
    "2. Brian Waweru\n",
    "3. Pamela Godia\n",
    "4. Hellen Mwaniki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5bcc01",
   "metadata": {},
   "source": [
    "## 1. Project Overview \n",
    "\n",
    "\n",
    "This project aims to develop a natural language chatbot that can generate human-like responses by learning from real-world conversations. Leveraging dialogue data from YouTube videos and movie scripts, the chatbot will be trained to understand conversational flow and context. The Cornell Movie Dialogues Corpus will serve as the primary training dataset, enabling the model to grasp nuances in dialogue structure, character interactions, and contextual relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee6a2e",
   "metadata": {},
   "source": [
    "## 1.1 Problem Statement\n",
    "Traditional rule-based chatbots often produce rigid, context-insensitive responses that break the natural flow of conversation. To build a more engaging and realistic conversational experience, this project will leverage deep learning techniques on real-world dialogue data. The goal is to develop a chatbot capable of understanding and generating coherent, context-aware responses in multi-turn conversations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a75c93e",
   "metadata": {},
   "source": [
    "## 1.2 Objectives\n",
    "\n",
    "- Scrape and preprocess real dialogue data from YouTube and integrate it with the Cornell Movie Dialogues Corpus\n",
    "\n",
    "- Structure the dataset for effective training and evaluation\n",
    "\n",
    "- Train a sequence-to-sequence chatbot model using RNNs or LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d69050",
   "metadata": {},
   "source": [
    "## Youtube Data Scrapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f51945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (2.176.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-python-client) (2.40.3)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-python-client) (2.25.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > \"3.0\" in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (2.4.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.2.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.4)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.25.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.10)\n"
     ]
    }
   ],
   "source": [
    "! pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f23775a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import csv\n",
    "\n",
    "# Replace with your YouTube API key\n",
    "API_KEY = 'AIzaSyAL-zoRJClDhT9CszYblZbf7CdmAn3NJxI'\n",
    "\n",
    "# Initialize YouTube API client\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7809d710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching comments for video: qlZM3McwO1Q\n",
      "Fetching comments for video: -voTKRBOEd0\n",
      "Fetching comments for video: 7JwKc6r5fAQ\n",
      "Fetching comments for video: _b6D5wMzKZQ\n",
      "Fetching comments for video: IB12MAwLs58\n",
      "Fetching comments for video: QzIkndzWYU4\n",
      "Fetching comments for video: P0cwqhA-YCk\n",
      "Fetching comments for video: q4sWUJxjc4g\n",
      "\n",
      "Total comments collected: 25629\n"
     ]
    }
   ],
   "source": [
    "def get_comments_with_replies(video_id):\n",
    "    comments = []\n",
    "    \n",
    "    try:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet,replies\",\n",
    "            videoId=video_id,\n",
    "            maxResults=100,\n",
    "            textFormat=\"plainText\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        while request:\n",
    "            for item in response.get(\"items\", []):\n",
    "                top_comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                comments.append({\"video_id\": video_id, \"comment\": top_comment})\n",
    "                \n",
    "                # Add replies if any\n",
    "                replies = item.get(\"replies\", {}).get(\"comments\", [])\n",
    "                for reply in replies:\n",
    "                    reply_text = reply[\"snippet\"][\"textDisplay\"]\n",
    "                    comments.append({\"video_id\": video_id, \"comment\": reply_text})\n",
    "            \n",
    "            # Pagination\n",
    "            if \"nextPageToken\" in response:\n",
    "                request = youtube.commentThreads().list(\n",
    "                    part=\"snippet,replies\",\n",
    "                    videoId=video_id,\n",
    "                    maxResults=100,\n",
    "                    pageToken=response[\"nextPageToken\"],\n",
    "                    textFormat=\"plainText\"\n",
    "                )\n",
    "                response = request.execute()\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    except HttpError as e:\n",
    "        print(f\"Failed to fetch comments for video {video_id}: {e}\")\n",
    "    \n",
    "    return comments\n",
    "\n",
    "# List of video IDs\n",
    "video_ids = [\n",
    "    'qlZM3McwO1Q',\n",
    "    '-voTKRBOEd0',\n",
    "    '7JwKc6r5fAQ',\n",
    "    '_b6D5wMzKZQ',\n",
    "    'IB12MAwLs58',\n",
    "    'QzIkndzWYU4',\n",
    "    'P0cwqhA-YCk',\n",
    "    'q4sWUJxjc4g'\n",
    "]\n",
    "\n",
    "# Collect comments for all videos\n",
    "all_comments = []\n",
    "\n",
    "for vid in video_ids:\n",
    "    print(f\"Fetching comments for video: {vid}\")\n",
    "    video_comments = get_comments_with_replies(vid)\n",
    "    all_comments.extend(video_comments)\n",
    "\n",
    "print(f\"\\nTotal comments collected: {len(all_comments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eebb639f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Comments exported to 'youtube_comments.csv' successfully.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Export comments to a CSV file\n",
    "csv_filename = \"youtube_comments.csv\"\n",
    "\n",
    "if all_comments and isinstance(all_comments[0], dict):\n",
    "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"video_id\", \"comment\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_comments)\n",
    "\n",
    "    print(f\"✅ Comments exported to '{csv_filename}' successfully.\")\n",
    "else:\n",
    "    print(\"⚠️ No structured comment data available to export.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e60c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ba8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "df = pd.read_csv('youtube_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97692fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qlZM3McwO1Q</td>\n",
       "      <td>What an incredible victory. I agree the Kenyan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qlZM3McwO1Q</td>\n",
       "      <td>❤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qlZM3McwO1Q</td>\n",
       "      <td>“Claudia is an amazonian goddess with a beauti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qlZM3McwO1Q</td>\n",
       "      <td>Proud of my motherland Kenya ❤❤❤and Africa.at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qlZM3McwO1Q</td>\n",
       "      <td>Damn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment\n",
       "0  qlZM3McwO1Q  What an incredible victory. I agree the Kenyan...\n",
       "1  qlZM3McwO1Q                                                  ❤\n",
       "2  qlZM3McwO1Q  “Claudia is an amazonian goddess with a beauti...\n",
       "3  qlZM3McwO1Q  Proud of my motherland Kenya ❤❤❤and Africa.at ...\n",
       "4  qlZM3McwO1Q                                               Damn"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54999711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25629 entries, 0 to 25628\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   video_id  25629 non-null  object\n",
      " 1   comment   25628 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 400.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# information of the data\n",
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
